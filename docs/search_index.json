[["index.html", "Hyaluronic Acid Forecasting Chapter 1 Summary 1.1 Business Summary 1.2 Technical Executive Summary 1.3 Next Steps", " Hyaluronic Acid Forecasting Mary Grace Stachnik 2025-01-12 Chapter 1 Summary 1.1 Business Summary My forecast for Hyaluronic Acid Serum for Clinic G during Q3 (July-September) 2024 is 168 units. In preparation for sales in Q3, I would encourage Clinic G to order approximately 168 serums in June, if ordering for the quarter, or 56 serums, if ordering for only the next month, July. This forecast is within a 25% error, so based on upcoming promotional sales or the discretion of the Clinic G owner, this number could be dropped to 126 units for Q3 (42 units per month) or increased to 210 units (70 units per month). 1.2 Technical Executive Summary Objective: Forecast Hyaluronic Acid Serum demand at Skin Laundry Clinic G for Q3 of 2024. The first step in this project was to perform data cleaning. I filtered the sales dataset to include only observations for Hyaluronic Acid at Clinic G from January 2022 through September 2024. I then grouped sales by quarter. To add in more relevant information for an accurate forecast, I used the promotions dataset to determine the total number of days within each quarter in which there was a promotion running. Finally, I transformed the series into a time series object, and split into training (2022-2023), validation (Q1-Q2 2024), and test (Q3 2024) datasets. I used the training dataset to build the models and the validation to determine accuracy. The test dataset was not included in any of the model-building process to prevent overfitting, and accuracy was only calculated for the final selected model. Next, I tested 3 types of models: Exponential Smoothing, ARIMAX with quarterly dummy variables and promotional sales dynamic regression, and Prophet with a regressor variable for promotional sales. Because of the limited data, with only 8 quarters in the training dataset, the Exponential Smoothing and ARIMAX models were unable to pick up on seasonality signal. The final model I chose and applied to the test dataset was a Prophet Model with linear trend and multiplicative yearly seasonality. This model also included a regressor varible for the number of days within a quarter that there was a promotion running. The Ljung Box test for this model showed no remaining autocorrelation. Finally, I determined the final forecast for Hyaluronic Acid Serum at Clinic G in Q3 2024 using the Prophet model. Since this was in the past, I was able to calculate the final accuracy, but this information was NOT used to further tune the model. Final Forecast: 168 Final Mean Absolute Percentage Error (MAPE): 25.6% 1.3 Next Steps The next steps I would take in this project are the following: Build more complex models with monthly aggregated data instead of quarterly aggregated data. This could find seasonal patterns that were not uncovered in the current modeling. Split the promotional days into each separate promotion. Since the Hyaluronic Acid serum was included in each promotion, I considered them all equal, but looking at each type of promotion could uncover more insights. Continue to gather more data to improve ESM and SARIMAX forecasting. Because I only had 2 periods of data, some of the more complex models would not run. I believe that simply having another year of data would resolve this issue. Combine models. I did try to combine the Prophet and ARIMAX models, but it was not any more accurate on the validation set than the Prophet alone. After gathering more data, this could help pick up on additional signal the Prophet did not capture. "],["data-analysis-and-cleaning.html", "Chapter 2 Data Analysis and Cleaning 2.1 R Setup 2.2 Data Cleaning 2.3 Data Aggregations 2.4 Time Series Decomposition 2.5 Differencing 2.6 ACF and PACF Plots", " Chapter 2 Data Analysis and Cleaning 2.1 R Setup I loaded in relevant libraries and imported the sales and promotional datasets. # Load libraries library(ggplot2) library(tidyverse) library(dplyr) library(fpp3) library(fable) library(fabletools) library(lubridate) library(imputeTS) library(forecast) library(fable.prophet) # Read in data setwd(&#39;C:/Users/Mary Grace Stachnik/OneDrive/Desktop/IAA/Skin Laundry&#39;) sales &lt;- read.csv(&#39;2022-2024 Clinic Product Sales Data.csv&#39;) promotions &lt;- read.csv(&#39;Promotion details and dates.csv&#39;) setwd(&#39;C:/Users/Mary Grace Stachnik/OneDrive/Desktop/IAA/Skin Laundry/SkinLaundry_Forecasting&#39;) 2.2 Data Cleaning I converted all date columns from character to date types, extracted the Quarter of each observation, and calculated the number of promotional sales days in each quarter. Assumption: If a promotion spans across 2 months, it is counted in the quarter of the end month. # Convert sales date column from character to date format and extract Month and Year sales$sale.date &lt;- as.POSIXct(sales$sale.date, format = &quot;%m/%d/%Y&quot;) sales$sale.month &lt;- yearmonth(sales$sale.date) sales$sale.qtr &lt;- yearquarter(sales$sale.date) sales$sale.dummyqtr &lt;- as.factor(quarter(sales$sale.date)) # Convert promotion date columns from character to date format and extract Month and Year promotions$Start.Date &lt;- as.POSIXct(promotions$Start.Date, format = &quot;%m/%d/%Y&quot;) promotions$End.Date &lt;- as.POSIXct(promotions$End.Date, format = &quot;%m/%d/%Y&quot;) promotions$Start.Month &lt;- yearmonth(promotions$Start.Date) promotions$End.Month &lt;- yearmonth(promotions$End.Date) # Calculate the length of each promotion in days. promotions$promotion.qtr &lt;- yearquarter(promotions$End.Date) promotions$promotion.days &lt;- round(as.numeric(promotions$End.Date - promotions$Start.Date),0) 2.3 Data Aggregations I aggregated all data to the Quarter/Year level and summed the total sales and total promotional days. I joined the sales and promotional datasets. Assumption: Sales for Q3 2024 are pre-planned # Calculate total number of days a promotion is running during each quarter promotion.agg &lt;- promotions %&gt;% group_by(promotion.qtr) %&gt;% summarize(promotion.days = sum(promotion.days)) %&gt;% ungroup() # Filter to Hyaluronic Acid at Clinic G for Jan 2022 to Sep 2024 and group sales by month gha &lt;- sales %&gt;% filter(clinic.name==&quot;Clinic G&quot; &amp; product.name==&quot;Hyaluronic Acid Serum&quot; &amp; sale.date &lt; as.POSIXct(&#39;10/1/2024&#39;, format = &quot;%m/%d/%Y&quot;)) %&gt;% group_by(sale.qtr, sale.dummyqtr) %&gt;% summarize(total_hyaluronic = sum(quantity.sold)) %&gt;% ungroup() ## `summarise()` has grouped output by &#39;sale.qtr&#39;. You can override using the `.groups` argument. # Join promotion details onto dataset gha &lt;- left_join(gha, promotion.agg, by = c(&quot;sale.qtr&quot; = &quot;promotion.qtr&quot;)) gha ## # A tibble: 11 × 4 ## sale.qtr sale.dummyqtr total_hyaluronic promotion.days ## &lt;qtr&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2022 Q1 1 100 45 ## 2 2022 Q2 2 107 11 ## 3 2022 Q3 3 99 28 ## 4 2022 Q4 4 112 33 ## 5 2023 Q1 1 105 19 ## 6 2023 Q2 2 97 3 ## 7 2023 Q3 3 122 13 ## 8 2023 Q4 4 137 33 ## 9 2024 Q1 1 78 20 ## 10 2024 Q2 2 231 21 ## 11 2024 Q3 3 134 13 2.4 Time Series Decomposition I converted the series to a time series object, split into train, validation, and test datasets, and checked that there were no implicit or explicit missing time periods. I visualized the data using STL time series decomposition. The insights gained from visualization plus manually looking over the dataset include an increasing trend starting in the middle of 2023, seasonal spikes in April and November, and what seems to be an outlier value or the start of a new increased trend in sales in Q2 of 2024. #Convert series into a tsibble for time series analysis ha_ts &lt;- as_tsibble(gha, index=sale.qtr) # Create training, validation, and test datasets # 2022/2023 as training, Q1/Q2 2024 as validation, Q3 2024 as test train &lt;- ha_ts[1:8,] val &lt;- ha_ts[9:10,] train_val &lt;- dplyr::bind_rows(train,val) test &lt;- ha_ts[11,] # Determine if there are implicit or explicit time gaps in data #count_gaps(ha_ts) #scan_gaps(ha_ts) # Perform STL decomposition to visualize training/validation data, as well as trend and seasonal patterns dcmp &lt;- train_val %&gt;% model(stl = STL(total_hyaluronic)) components(dcmp) %&gt;% autoplot() + theme_classic() 2.5 Differencing I found that the optimal number of seasonal differences is 1, if using a seasonal ARIMA model. After taking 1 seasonal difference, no other differencing would be needed. # Determine optimal number of seasonal differences, assuming monthly season print(train %&gt;% features(total_hyaluronic, unitroot_nsdiffs)) #1 ## # A tibble: 1 × 1 ## nsdiffs ## &lt;int&gt; ## 1 1 # Determine if non-seasonal differences are needed after taking the 1st seasonal difference print(train %&gt;% mutate(ha_diff = difference(total_hyaluronic, lag=4)) %&gt;% features(ha_diff, unitroot_ndiffs)) #0 ## # A tibble: 1 × 1 ## ndiffs ## &lt;int&gt; ## 1 0 2.6 ACF and PACF Plots I found that there are no significant spikes in the ACF and PACF plots. If using an ARIMA model, this would correlate to (p,d,q) terms of (0,0,0). I found that after taking the first seasonal difference, there are also no significant spikes. If using a SARIMA model, this would correlate to (P,D,Q) terms of (0,1,0). # Check ACF and PACF with no seasonal differencing train %&gt;% gg_tsdisplay(total_hyaluronic, plot_type=&#39;partial&#39;) # No spikes, assume p=0,d=0,q=0 # Check ACF and PACF after taking 1 seasonal difference train %&gt;% gg_tsdisplay(difference(total_hyaluronic, lag=4), plot_type=&#39;partial&#39;,lag=8) # No spikes, assume P=0,D=1,Q=0 ## Warning: Removed 4 rows containing missing values or values outside the scale range ## (`geom_line()`). ## Warning: Removed 4 rows containing missing values or values outside the scale range ## (`geom_point()`). "],["modeling.html", "Chapter 3 Modeling 3.1 Exponential Smoothing Model 3.2 ARIMAX Model 3.3 Prophet Model 3.4 Combined Models 3.5 Final Forecast Accuracy", " Chapter 3 Modeling 3.1 Exponential Smoothing Model I used the autoETS() function to determine the optimal exponential smoothing model for the training data. My final ESM model had a multiplicative error term and no seasonal or trend terms. The model forecast 130 units of Hyaluronic Acid for both Q1 and Q2 2024 within the validation set, which corresponds to a MAPE of 55.2% The Ljung-Box test showed no remaining autocorrelation. # Train ESM model using the autoETS() function model_ETS &lt;- train %&gt;% model( autoETS = ETS(total_hyaluronic) ) model_ETS ## # A mable: 1 x 1 ## autoETS ## &lt;model&gt; ## 1 &lt;ETS(M,N,N)&gt; # Create a forecast for the validation set model_ETS_for &lt;- fabletools::forecast(model_ETS, val) model_ETS_for ## # A fable: 2 x 6 [1Q] ## # Key: .model [1] ## .model sale.qtr total_hyaluronic .mean sale.dummyqtr promotion.days ## &lt;chr&gt; &lt;qtr&gt; &lt;dist&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 autoETS 2024 Q1 N(130, 321) 130. 1 20 ## 2 autoETS 2024 Q2 N(130, 473) 130. 2 21 # Calculate accuracy for the ESM model on the validation set fabletools::accuracy(model_ETS_for, val) ## # A tibble: 1 × 10 ## .model .type ME RMSE MAE MPE MAPE MASE RMSSE ACF1 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 autoETS Test 24.5 80.3 76.5 -11.4 55.2 NaN NaN -0.5 # Check for any remaining autocorrelation using the ljung_box test augment(model_ETS) %&gt;% features(.innov,ljung_box, lag=4) # FTR, no autocorrelation ## # A tibble: 1 × 3 ## .model lb_stat lb_pvalue ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 autoETS 1.31 0.859 3.2 ARIMAX Model I used the auto ARIMA() function to determine the optimal ARIMAX mdoel for the training data. My final ARIMA model had (p,d,q,)(P,D,Q) terms of (0,0,0)(0,0,0). Seasonality was accounted for through quarterly dummy variables, and dynamic regression was used for the number of days within each quarter when a promotion was running. The model forecast 50 units of Hyaluronic Acid Q1 2024 and 137 units for Q2 2024 within the validation set, which corresponds to a MAPE of 38.1% The Ljung-Box test showed no remaining autocorrelation. # Train ARIMA Model using the auto ARIMA function, using dummy variables instead of seasonal terms model_SARIMAX &lt;- train %&gt;% model( autoARIMA=ARIMA(total_hyaluronic ~ sale.dummyqtr + promotion.days)) model_SARIMAX ## # A mable: 1 x 1 ## autoARIMA ## &lt;model&gt; ## 1 &lt;LM w/ ARIMA(0,0,0) errors&gt; # Create a forecast for the validation set model_SARIMAX_for &lt;- forecast(model_SARIMAX, val) model_SARIMAX_for ## # A fable: 2 x 6 [1Q] ## # Key: .model [1] ## .model sale.qtr total_hyaluronic .mean sale.dummyqtr promotion.days ## &lt;chr&gt; &lt;qtr&gt; &lt;dist&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 autoARIMA 2024 Q1 N(50, 1414) 50.3 1 20 ## 2 autoARIMA 2024 Q2 N(137, 1414) 137. 2 21 # Calculate accuracy for the ARIMAX model on the validation set fabletools::accuracy(model_SARIMAX_for, val) ## # A tibble: 1 × 10 ## .model .type ME RMSE MAE MPE MAPE MASE RMSSE ACF1 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 autoARIMA Test 60.8 69.2 60.8 38.1 38.1 NaN NaN -0.5 # Check for any remaining autocorrelation using the ljung_box test augment(model_SARIMAX) %&gt;% features(.innov, ljung_box, lag=4) # FTR, no autocorrelation ## # A tibble: 1 × 3 ## .model lb_stat lb_pvalue ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 autoARIMA 2.82 0.588 3.3 Prophet Model I used the Prophet() function to determine the optimal Prophet for the training data. My final Prophet model had linear growth and multiplicative yearly seasonality, and a regressor variable was used for the number of days within each quarter when a promotion was running. The model forecast 92 units of Hyaluronic Acid Q1 2024 and 219 units for Q2 2024 within the validation set, which corresponds to a MAPE of 11.9% This was our lowest MAPE on the validation set, so it was chosen as the final model. The Ljung-Box test showed no remaining autocorrelation. # Train Prophet Model, using a regressor variable for promotional days model_prophet_test &lt;- train %&gt;% model(prophet1 = prophet(total_hyaluronic ~ promotion.days + growth(&quot;linear&quot;) + season(period = &quot;year&quot;, type=&quot;multiplicative&quot;)), prophet2 = prophet(total_hyaluronic ~ promotion.days + growth(&quot;linear&quot;) + season(period = &quot;year&quot;, type=&quot;additive&quot;)) ) ## n.changepoints greater than number of observations. Using 5 ## n.changepoints greater than number of observations. Using 5 model_prophet &lt;- train %&gt;% model(prophet1 = prophet(total_hyaluronic ~ xreg(promotion.days) + growth(&quot;linear&quot;) + season(period = &quot;year&quot;, type=&quot;multiplicative&quot;))) ## n.changepoints greater than number of observations. Using 5 # Create a forecast for the validation set model_prophet_for &lt;- fabletools::forecast(model_prophet, val) model_prophet_for ## # A fable: 2 x 6 [1Q] ## # Key: .model [1] ## .model sale.qtr total_hyaluronic .mean sale.dummyqtr promotion.days ## &lt;chr&gt; &lt;qtr&gt; &lt;dist&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 prophet1 2024 Q1 sample[5000] 92.5 1 20 ## 2 prophet1 2024 Q2 sample[5000] 219. 2 21 # Calculate accuracy for the Prophet model on the validation set fabletools::accuracy(model_prophet_for, val) ## # A tibble: 1 × 10 ## .model .type ME RMSE MAE MPE MAPE MASE RMSSE ACF1 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 prophet1 Test -1.20 13.3 13.3 -6.67 11.9 NaN NaN -0.5 # Check for any remaining autocorrelation using the ljung_box test augment(model_prophet) %&gt;% features(.innov, ljung_box, lag=4) # FTR, no autocorrelation ## # A tibble: 1 × 3 ## .model lb_stat lb_pvalue ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 prophet1 5.81 0.214 3.4 Combined Models I combined all three models, as well as ESM+Prophet and ARIMAX+Prophet. The accuracy on the combined models was lower than the Prophet on its own, so combinations were not used as the final model. # Combined Models model_all &lt;- train %&gt;% model( esm = ETS(total_hyaluronic), arimax = ARIMA(total_hyaluronic ~ sale.dummyqtr + promotion.days), prophet = prophet(total_hyaluronic ~ xreg(promotion.days) + growth(&quot;linear&quot;) + season(period = &quot;year&quot;, type=&quot;multiplicative&quot;)) ) %&gt;% mutate(combo = (esm+arimax+prophet)/3, combo2 = (esm+prophet)/2, combo3 = (arimax+prophet)/2) ## n.changepoints greater than number of observations. Using 5 model_all ## # A mable: 1 x 6 ## esm arimax prophet combo combo2 combo3 ## &lt;model&gt; &lt;model&gt; &lt;model&gt; &lt;model&gt; &lt;model&gt; &lt;model&gt; ## 1 &lt;ETS(M,N,N)&gt; &lt;LM w/ ARIMA(0,0,0) errors&gt; &lt;prophet&gt; &lt;COMBINATION&gt; &lt;COMBINATION&gt; &lt;COMBINATION&gt; # Create a forecast for the validation set model_all_for &lt;- fabletools::forecast(model_all, val) model_all_for ## # A fable: 12 x 6 [1Q] ## # Key: .model [6] ## .model sale.qtr total_hyaluronic .mean sale.dummyqtr promotion.days ## &lt;chr&gt; &lt;qtr&gt; &lt;dist&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 esm 2024 Q1 N(130, 321) 130. 1 20 ## 2 esm 2024 Q2 N(130, 473) 130. 2 21 ## 3 arimax 2024 Q1 N(50, 1414) 50.3 1 20 ## 4 arimax 2024 Q2 N(137, 1414) 137. 2 21 ## 5 prophet 2024 Q1 sample[5000] 92.5 1 20 ## 6 prophet 2024 Q2 sample[5000] 219. 2 21 ## 7 combo 2024 Q1 90.90699 90.9 1 20 ## 8 combo 2024 Q2 162.0223 162. 2 21 ## 9 combo2 2024 Q1 111.2171 111. 1 20 ## 10 combo2 2024 Q2 174.4336 174. 2 21 ## 11 combo3 2024 Q1 71.38409 71.4 1 20 ## 12 combo3 2024 Q2 178.0584 178. 2 21 # Calculate accuracy for the combined models on the validation set fabletools::accuracy(model_all_for, val) ## # A tibble: 6 × 10 ## .model .type ME RMSE MAE MPE MAPE MASE RMSSE ACF1 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 arimax Test 60.8 69.2 60.8 38.1 38.1 NaN NaN -0.5 ## 2 combo Test 28.0 49.6 40.9 6.66 23.2 NaN NaN -0.5 ## 3 combo2 Test 11.7 46.4 44.9 -9.05 33.5 NaN NaN -0.5 ## 4 combo3 Test 29.8 37.7 29.8 15.7 15.7 NaN NaN -0.5 ## 5 esm Test 24.5 80.3 76.5 -11.4 55.2 NaN NaN -0.5 ## 6 prophet Test -1.20 13.3 13.3 -6.67 11.9 NaN NaN -0.5 3.5 Final Forecast Accuracy The final model was the Prophet model, corresponding to a MAPE of 11.9% on the validation. I combined the training and validation sets to update the model parameters before forecasting the test dataset, or Q3 2024. The final model had a prediction of 168 units of Hyaluronic Acid for Clinic G, corresponding to a MAPE of 25.6%. # Use combined training and validation to create final prophet model for 2024 Q3 prediction model_final &lt;- train_val %&gt;% model( prophetfinal = prophet(total_hyaluronic ~ xreg(promotion.days) + growth(&quot;linear&quot;) + season(period = &quot;year&quot;, type=&quot;multiplicative&quot;)) ) ## n.changepoints greater than number of observations. Using 7 # Predict final forecast for Q3 2024 using the final model prophet_forecast_final &lt;- model_final %&gt;% select(prophetfinal) %&gt;% fabletools::forecast(test) prophet_forecast_final ## # A fable: 1 x 6 [1Q] ## # Key: .model [1] ## .model sale.qtr total_hyaluronic .mean sale.dummyqtr promotion.days ## &lt;chr&gt; &lt;qtr&gt; &lt;dist&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 prophetfinal 2024 Q3 sample[5000] 168. 3 13 # Calculate final accuracy for Q3 2024 forecast fabletools::accuracy(prophet_forecast_final, test) ## Warning: 1 error encountered ## [1] subscript out of bounds ## # A tibble: 1 × 10 ## .model .type ME RMSE MAE MPE MAPE MASE RMSSE ACF1 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 prophetfinal Test -34.3 34.3 34.3 -25.6 25.6 NaN NaN NA "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
